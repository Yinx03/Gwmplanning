wandb:
  entity: null
#  run_id: askkz9i2
  resume: 'auto'
logger_level: 'info'
logger_format_string: null
gpu: True
experiment:
    base_root: '' #path/to/root
    project: "sft_navsim"
    name: "sft_planning"
    output_dir: "${experiment.base_root}/resume_checkpoint/sft_navsim"
    max_train_examples_mmu: 50000
    save_every: 5000
    eval_every: 5000
    generate_every: 200
    log_every: 50
    log_grad_norm_every: 500000
    eval_from_checkpoint: True
    eval_only: True #False
    resume_dir: ""
    img_show_path: '${experiment.base_root}/visual_show/sft/navsim'
    text_root: '${experiment.base_root}/resume_checkpoint/sft_navsim/text_pair'
    add_ego: true #
    add_cmd: true
    nfp_loss:
      alpha_coffe: 1.0
      beta_coffe: 0.4 #0.4
    eval:
      use_fvd: True
      max_eval_iters: 10000
      use_frame_metrics: True
      eval_generate_times: 4
      max_generate_batchsize: 20
      action_conditioned: True
      max_decode_batchsize: 2
      use_text_metrics: True
      use_trj_metrics: True
      eval_dir: ""# path/to/ckpt

model:
    vq_model:
        type: "Compressive_magvit_v2"
        vq_model_name: "${experiment.base_root}/checkpoints/magvitv2"
        mask_l: 0
        mask_h: 1
        latent_size: 4
        patch_size: 2
        num_vq_embeddings: 8192
        num_dyn_embeddings: 8192
        pretrained_model_path: "" #path/to/vq_tokenizer/diffusion_pytorch_model.safetensors
    cond_enable: true #false
    showo:
        load_from_showo: True #False
        pretrained_model_path: "${experiment.base_root}/checkpoints/show-o-w-clip-vit"
        w_clip_vit: False #True
        vocab_size: 58498
        llm_vocab_size: 50295
        llm_model_path: '${experiment.base_root}/checkpoints/phi-1_5'
        codebook_size: 8192
        num_vq_tokens: 256
        num_new_special_tokens: 10  # <|soi|> <|eoi|> <|sov|> <|eov|> <|t2i|> <|mmu|> <|t2v|> <|v2v|> <|lvg|> <|pad|>
        dynamic_size: 8192
        resume_from_pretrain: "" # path/to/pretrainedmodel/pytorch_model.bin'
    eval:
        i3d_path: '${experiment.base_root}/checkpoints/i3d/i3d_torchscript.pt'
    gradient_checkpointing: True

dataset:
    dataset_use: "sft_navsim"
    clip_img_token: -200
    clip_vq_token: -100
    nuplan_10hz_blobs: '${experiment.base_root}/dataset/navsim/nuplan_scene_blobs'
    nuplan_10hz_logs: '${experiment.base_root}/dataset/navsim/nuplan_img_logs'
    navsim_root: '${experiment.base_root}/dataset/navsim'
    navsim_log_path: ''
    logs_file:
        train_split: 'trainval'
        test_split: 'test'
    scene_filter:
        filter_root: '${experiment.base_root}/navsim/planning/script/config/common/train_test_split/scene_filter'
        train_split: 'navtrain'
        test_split: 'navtest'
        train_cache: 'navtrain_cache'
        test_cache: 'navtest_cache'
    scoring_path: '${experiment.base_root}/navsim/planning/script/config/pdm_scoring/default_scoring_parameters.yaml'
    proposal_sampling:
        num_poses: 40
        # [s] the time horizon of a trajectory
        time_horizon: null #
        # [s] length of an interval between two states
        interval_length: 0.1

    params:
        add_caption_prompt: True
        shuffle_buffer_size: 1000
        num_workers: 8 #32
        pin_memory: True
        persistent_workers: True
        context_length: 2
        resolution_h: 128
        resolution_w: 224
    preprocessing:
        max_seq_length: 3000
        resolution: [256, 448]
        center_crop: False
        random_flip: False
    ctd:
      context_length: 2
      condition_length: 2
      segment_horizon: 21
      segment_length: 21
      d_resolution: [128,224]
      c_resolution: [256,448]
      fps: 10
      split_frames: 5
      prev_frames: 20
      next_frames: 10
      views:
        CAM_F0: '/nuscenes_front'
        CAM_L0: ''
        CAM_L1: ''
        CAM_L2: ''
        CAM_R0: ''
        CAM_R1: ''
        CAM_R2: ''
        CAM_B0: ''

      navsim_data_path: '/navsim'

worker: "${experiment.base_root}/navsim/planning/script/config/common/worker/single_machine_thread_pool.yaml"

optimizer:
    name: adamw
    params: # default adamw params
        learning_rate: 3e-5
        scale_lr: False
        beta1: 0.9
        beta2: 0.999
        weight_decay: 0.01
        epsilon: 1e-8

lr_scheduler:
    scheduler: "cosine"
    params:
        learning_rate: ${optimizer.params.learning_rate}
        warmup_steps: 1000

training:
    gradient_accumulation_steps: 4
    batch_size_train_nus: 7
    batch_size_val_nus: 20
    mixed_precision: "bf16"
    enable_tf32: True
    seed: 10086
    num_workers: 10
    eval_start_epoch: 10
    save_start_epoch: 10
    max_train_steps: 160000
    overfit_one_batch: False
    cond_dropout_prob: 0.1
    min_masking_rate: 0.0
    label_smoothing: 0.0
    max_grad_norm: 4.0 #null
    guidance_scale: 0.0
    lora_enable: False
    video_coeff: 0.3
    tj_coeff: 1.0 #1.0
    motion_weight: True
